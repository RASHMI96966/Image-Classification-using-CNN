{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<font size=\"+3\" color=blue><b> <center><u> Image Classification using CNNs </u></center></b></font>","metadata":{}},{"cell_type":"markdown","source":"<font color=\"green\" size=+2.5><b>Objective</b></font>\n\nThe aim of this kernel is to classify outdoor scene. This kernel will hold almost all steps and steps required to implement image classification algorithm using deep learning on Intel Scene Classification dataset.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n<font color=\"green\" size=+2.5><b>Import Libraries</b></font>\n","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt             \nimport tensorflow as tf\nfrom tensorflow import keras \nimport tensorflow.keras.models as Models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator   # generates batches of augmented data\nfrom tensorflow.keras.preprocessing import image                      # functions for image preprocessing\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nimport cv2\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:34:59.519202Z","iopub.execute_input":"2024-01-14T02:34:59.519984Z","iopub.status.idle":"2024-01-14T02:34:59.525897Z","shell.execute_reply.started":"2024-01-14T02:34:59.519947Z","shell.execute_reply":"2024-01-14T02:34:59.524738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (228, 228)\n\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:35:03.839673Z","iopub.execute_input":"2024-01-14T02:35:03.841109Z","iopub.status.idle":"2024-01-14T02:35:03.846297Z","shell.execute_reply.started":"2024-01-14T02:35:03.841056Z","shell.execute_reply":"2024-01-14T02:35:03.845070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n<font color=\"green\" size=+2.5><b>Loading the Data</b></font>","metadata":{}},{"cell_type":"code","source":"train_dir='/kaggle/input/intel-image-classification/seg_train/seg_train'\ntest_dir='/kaggle/input/intel-image-classification/seg_test/seg_test'","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:35:06.884366Z","iopub.execute_input":"2024-01-14T02:35:06.884898Z","iopub.status.idle":"2024-01-14T02:35:06.890300Z","shell.execute_reply.started":"2024-01-14T02:35:06.884857Z","shell.execute_reply":"2024-01-14T02:35:06.888831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.keras.utils.image_dataset_from_directory(\n  train_dir,\n  seed=123,              #sets the random seed for shuffling the dataset . Setting a seed ensures reproducibility.\n  image_size=IMAGE_SIZE,\n  batch_size=BATCH_SIZE)           # training dataset ","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:35:11.539376Z","iopub.execute_input":"2024-01-14T02:35:11.539805Z","iopub.status.idle":"2024-01-14T02:35:19.937167Z","shell.execute_reply.started":"2024-01-14T02:35:11.539770Z","shell.execute_reply":"2024-01-14T02:35:19.936013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  test_dir,\n  seed=123,             #sets the random seed for shuffling the dataset. Setting a seed ensures reproducibility.\n  image_size=IMAGE_SIZE,\n  batch_size=BATCH_SIZE)        # validation dataset ","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:35:22.349202Z","iopub.execute_input":"2024-01-14T02:35:22.349600Z","iopub.status.idle":"2024-01-14T02:35:22.852580Z","shell.execute_reply.started":"2024-01-14T02:35:22.349567Z","shell.execute_reply":"2024-01-14T02:35:22.851709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can find the class names in the class_names attribute on these datasets.","metadata":{}},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)      # an attribute printing labels present in dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:35:25.689330Z","iopub.execute_input":"2024-01-14T02:35:25.689736Z","iopub.status.idle":"2024-01-14T02:35:25.694738Z","shell.execute_reply.started":"2024-01-14T02:35:25.689701Z","shell.execute_reply":"2024-01-14T02:35:25.693838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n<font color=\"green\" size=+2.5><b>Visualize the data</b></font>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):   #one batch at a time\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)      # subplot in 3x3 grid\n        plt.imshow(images[i].numpy().astype(\"uint8\"))  # tensor to array , pixel values as unsigned 8 bit integers\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")                    #turns off axis labels","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:35:28.599288Z","iopub.execute_input":"2024-01-14T02:35:28.600032Z","iopub.status.idle":"2024-01-14T02:35:30.500596Z","shell.execute_reply.started":"2024-01-14T02:35:28.599995Z","shell.execute_reply":"2024-01-14T02:35:30.499125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n<font color=\"green\" size=+2.5><b>Beginner: Simple Model Creation</b></font>","metadata":{}},{"cell_type":"markdown","source":"## Steps are:\n\n1. Build the model,\n2. Compile the model,\n3. Train / fit the data to the model,\n4. Evaluate the model on the testing set,\n\n- Conv2D: (32 filters of size 3 by 3) The features will be \"extracted\" from the image.\n- MaxPooling2D: The images get half sized.\n- Flatten: Transforms the format of the images from a 2d-array to a 1d-array of 150 150 3 pixel values.\n- Relu : given a value x, returns max(x, 0).\n- Softmax: 6 neurons, probability that the image belongs to one of the classes.","metadata":{}},{"cell_type":"code","source":"num_classes = len(class_names)     # number of labels in dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:35:56.569643Z","iopub.execute_input":"2024-01-14T02:35:56.570056Z","iopub.status.idle":"2024-01-14T02:35:56.575020Z","shell.execute_reply.started":"2024-01-14T02:35:56.570020Z","shell.execute_reply":"2024-01-14T02:35:56.574132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Models.Sequential()   # Sequential model with linear stack of layers\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(228,228,3)))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))  #downsample  the spatial dimensions of the feature maps.\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2,2))\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2,2))\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2,2))\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2,2))\nmodel.add(tf.keras.layers.Flatten())      #3D output to 1D vector before adding fully connected layers\nmodel.add(tf.keras.layers.Dense(1024, activation='relu'))   # dense layer with 1024 units\nmodel.add(tf.keras.layers.Dropout(0.2))   #  droupout rate 0.2 , regularization , preventing overfitting\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(num_classes, activation='softmax')) # final output probabilites for each class , units is num_classes ","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:35:58.959352Z","iopub.execute_input":"2024-01-14T02:35:58.959733Z","iopub.status.idle":"2024-01-14T02:35:59.177693Z","shell.execute_reply.started":"2024-01-14T02:35:58.959704Z","shell.execute_reply":"2024-01-14T02:35:59.176482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:36:02.624200Z","iopub.execute_input":"2024-01-14T02:36:02.625523Z","iopub.status.idle":"2024-01-14T02:36:02.672741Z","shell.execute_reply.started":"2024-01-14T02:36:02.625474Z","shell.execute_reply":"2024-01-14T02:36:02.671684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(     # learning process before training the model\n  optimizer='adam',  # adaptive moment estimation\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # minimum loss during training, multiclass problem , raw logits output\n  metrics=['accuracy']) # display classification accuracy","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:36:06.159129Z","iopub.execute_input":"2024-01-14T02:36:06.159811Z","iopub.status.idle":"2024-01-14T02:36:06.181849Z","shell.execute_reply.started":"2024-01-14T02:36:06.159769Z","shell.execute_reply":"2024-01-14T02:36:06.180990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nearlystopping = EarlyStopping(monitor='val_loss',\n                                              patience=5, # stop after  5 epochs if validation loss not improve\n                                              verbose=1, #  for display\n                                              mode='min'\n                                              )\ncheckpointer = ModelCheckpoint(filepath='bestvalue', verbose=0, save_best_only=True)\ncallback_list = [checkpointer, earlystopping] # list passed to fit method for training","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:36:08.569448Z","iopub.execute_input":"2024-01-14T02:36:08.570568Z","iopub.status.idle":"2024-01-14T02:36:08.575222Z","shell.execute_reply.started":"2024-01-14T02:36:08.570527Z","shell.execute_reply":"2024-01-14T02:36:08.574454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_ds,                 \n    validation_data=val_ds,  \n    epochs=35,               # Number of times model will iterate\n    callbacks=callback_list   # List of callbacks to be applied during training\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T02:36:18.479873Z","iopub.execute_input":"2024-01-14T02:36:18.480250Z","iopub.status.idle":"2024-01-14T04:08:44.252137Z","shell.execute_reply.started":"2024-01-14T02:36:18.480221Z","shell.execute_reply":"2024-01-14T04:08:44.251040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Summary","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:20:54.469551Z","iopub.execute_input":"2024-01-14T04:20:54.470570Z","iopub.status.idle":"2024-01-14T04:20:54.516456Z","shell.execute_reply.started":"2024-01-14T04:20:54.470529Z","shell.execute_reply":"2024-01-14T04:20:54.515345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.xlabel('Epoch Number')\nplt.ylabel('Loss')\nplt.plot(history.history['loss'], label='training set')\nplt.plot(history.history['val_loss'], label='test set')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:20:58.558521Z","iopub.execute_input":"2024-01-14T04:20:58.558916Z","iopub.status.idle":"2024-01-14T04:21:05.865264Z","shell.execute_reply.started":"2024-01-14T04:20:58.558884Z","shell.execute_reply":"2024-01-14T04:21:05.863936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.xlabel('Epoch Number')\nplt.ylabel('Accuracy')\nplt.plot(history.history['accuracy'], label='training set')\nplt.plot(history.history['val_accuracy'], label='test set')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:21:10.138746Z","iopub.execute_input":"2024-01-14T04:21:10.139167Z","iopub.status.idle":"2024-01-14T04:21:10.881816Z","shell.execute_reply.started":"2024-01-14T04:21:10.139136Z","shell.execute_reply":"2024-01-14T04:21:10.880701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction on unseen image data","metadata":{}},{"cell_type":"code","source":"# load the predicted data and predict class on unseen data\ndef getImagePaths(path):\n    image_names = []\n    for dirname, _, filenames in os.walk(path):  # iterate all files in a directory \n        for filename in filenames:\n            fullpath = os.path.join(dirname, filename)   # create fullpath\n            image_names.append(fullpath)\n    return image_names\n\npred_dir = '../input/intel-image-classification/seg_pred/seg_pred'\n\nimages_paths = getImagePaths(pred_dir)\nlen(images_paths)    # total number of images ","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:21:17.749349Z","iopub.execute_input":"2024-01-14T04:21:17.750057Z","iopub.status.idle":"2024-01-14T04:21:27.880849Z","shell.execute_reply.started":"2024-01-14T04:21:17.750019Z","shell.execute_reply":"2024-01-14T04:21:27.879895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# images path list to numpy array using cv2.imread module\nfile_array = []\n\nfor file in images_paths[:9]:\n    img_ = image.load_img(file, target_size=(228, 228))\n    img_array = image.img_to_array(img_)       # image to array having pixel values \n    img_processed = np.expand_dims(img_array, axis=0)  # adds extra dimension to array\n    img_processed /= 255.    # normalize pixel size to  [0,1] range \n    file_array.append(img_processed)    \n    \nfile_array = np.array(file_array)     # whole list to array ","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:21:42.509940Z","iopub.execute_input":"2024-01-14T04:21:42.510635Z","iopub.status.idle":"2024-01-14T04:21:42.611269Z","shell.execute_reply.started":"2024-01-14T04:21:42.510597Z","shell.execute_reply":"2024-01-14T04:21:42.610229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = train_ds.class_names\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:21:46.118399Z","iopub.execute_input":"2024-01-14T04:21:46.118797Z","iopub.status.idle":"2024-01-14T04:21:46.123695Z","shell.execute_reply.started":"2024-01-14T04:21:46.118765Z","shell.execute_reply":"2024-01-14T04:21:46.122951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_image(filename, model):\n    img_ = image.load_img(filename, target_size=(228, 228))\n    img_array = image.img_to_array(img_)        # image to array having pixel values \n    img_processed = np.expand_dims(img_array, axis=0) # adds extra dimension to array\n    img_processed /= 255.                      # normalize pixel size to  [0,1] range \n    \n    prediction = model.predict(img_processed)  # holds result  that is a vector of probabilities for each class.\n    \n    index = np.argmax(prediction)     #Finds the index of the class with the highest probability \n    \n    plt.title(\"Prediction - {}\".format(str(classes[index]).title()), size=18, color='red')\n    plt.imshow(img_array)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:21:49.053808Z","iopub.execute_input":"2024-01-14T04:21:49.054186Z","iopub.status.idle":"2024-01-14T04:21:49.060800Z","shell.execute_reply.started":"2024-01-14T04:21:49.054156Z","shell.execute_reply":"2024-01-14T04:21:49.059549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_image('/kaggle/input/intel-image-classification/seg_pred/seg_pred/2138.jpg',model)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T05:50:12.971896Z","iopub.execute_input":"2024-01-14T05:50:12.972342Z","iopub.status.idle":"2024-01-14T05:50:13.424646Z","shell.execute_reply.started":"2024-01-14T05:50:12.972310Z","shell.execute_reply":"2024-01-14T05:50:13.423775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}